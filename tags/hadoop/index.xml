<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>hadoop on FIFCOM实验室</title>
    <link>https://blog.fifcom.cn/tags/hadoop/</link>
    <description>Recent content in hadoop on FIFCOM实验室</description>
    <image>
      <url>https://fifcom.cn/avatar/?transparent=1</url>
      <link>https://fifcom.cn/avatar/?transparent=1</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 30 Mar 2022 00:00:00 +0800</lastBuildDate><atom:link href="https://blog.fifcom.cn/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HBase安装</title>
      <link>https://blog.fifcom.cn/posts/hadoop-hbase-install/</link>
      <pubDate>Wed, 30 Mar 2022 00:00:00 +0800</pubDate>
      
      <guid>https://blog.fifcom.cn/posts/hadoop-hbase-install/</guid>
      <description>安装HBase 环境准备 首先应完成完全分布式安装Hadoop
并配置免密登录、上传Zookeeper、HBase安装包至master节点
配置Zookeeper 解压Zookeeper安装包
tar -zxvf apache-zookeeper-3.8.0-bin.tar.gz -C /opt 在解压目录创建data和log目录
cd /opt/apache-zookeeper-3.8.0-bin mkdir data log 编辑配置文件：复制conf目录下的样例文件，并修改dataDir(数据文件目录)和dataLogDir(日志文件目录)
cd conf cp zoo_sample.cfg zoo.cfg vi zoo.cfg =&amp;gt; dataDir=/opt/apache-zookeeper-3.8.0-bin/data dataLogDir=/opt/apache-zookeeper-3.8.0-bin/log 在data目录中新建myid文件，向里面写入1。这里的1表示是集群的第几台机器，slave节点则这里为2，3，4&amp;hellip;
cd ../data/ echo 1 &amp;gt;&amp;gt; myid 再次编辑zoo.cfg，添加主节点和从节点地址
cd ../conf/ vi zoo.cfg =&amp;gt; # 底部添加 server.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888 接着将Zookeeper安装文件分发到子节点
scp -r /opt/apache-zookeeper-3.8.0-bin/ slave1:/opt/ scp -r /opt/apache-zookeeper-3.8.0-bin/ slave2:/opt/ 修改子节点上的myid
cd /opt/apache-zookeeper-3.8.0-bin/data/ echo 2 &amp;gt; myid # echo 3 &amp;gt; myid cat myid 启动Zookeeper 启动前需关闭防火墙，以及在master上启动Hadoop</description>
    </item>
    
    <item>
      <title>Hadoop 运行官方示例WordCount</title>
      <link>https://blog.fifcom.cn/posts/hadoop-wordcount-example/</link>
      <pubDate>Tue, 15 Mar 2022 00:00:00 +0800</pubDate>
      
      <guid>https://blog.fifcom.cn/posts/hadoop-wordcount-example/</guid>
      <description>运行官方示例WordCount 环境安装完成后输入jps确保有5+个进程： 本实验使用官方WordCount程序实现Java源码词语统计。
准备Java源码 首先进入Java安装目录，找到src.zip，解压到tmp中
cd /opt/jdk8u282-b08/ unzip -d tmp src.zip 接着将tmp中的所有.java文件拷贝到javasrc目录下，需要先创建javasrc文件夹
mkdir javasrc # 找到文件名匹配*.java的文件后执行 cp 命令复制文件。注意\;是-exec的结束标志 find tmp -name *.java -exec cp {} javasrc \; 上传文件至HDFS 由于Java源码大多为小文件，需要将这些文件合并成一个大文件。如果不这样做的话会由于io开销过大而导致运行时间过长。
此处使用appendToFile将本地的所有java文件上传到HDFS的input/data_file中
cd /opt/jdk8u282-b08 # 文件会上传到HDFS的/user/&amp;lt;login_user&amp;gt;/input/data_file中， # 该目录如果不存在则会自动创建 hadoop fs -appendToFile javasrc/*.java input/data_file hadoop fs -ls input hadoop fs -tail input/data_file # 查看末尾1KB的内容 运行WordCount 官方示例文件在/opt/hadoop~/share/hadoop/mapreduce/hadoop-mapreduce-examples-~.jar中
hadoop jar命令用于执行jar文件，wordcount是例子的主类[?]，input是输入文件所在目录，output是输出文件所在目录。output目录不能事先存在。
hadoop jar /opt/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount input output 可以看到map和reduce操作是并行进行的
查看输出结果 查看HDFS中的output文件夹
hadoop fs -ls output 当运行成功后会在该文件下生成一个_SUCCESS文件，该文件长度为0，仅预示着成功输出了结果，其实际结果 存放在part-r-xxxxx文件中</description>
    </item>
    
    <item>
      <title>Hadoop 常用命令</title>
      <link>https://blog.fifcom.cn/posts/hadoop-commands/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:00 +0800</pubDate>
      
      <guid>https://blog.fifcom.cn/posts/hadoop-commands/</guid>
      <description>Hadoop常用命令 版本号 hadoop version 创建文件夹 hdfs dfs -mkdir /dir1 # 根目录下创建 列出文件和文件夹 展示根目录下所有文件和文件夹，及其信息
hdfs dfs -ls / 递归展示子文件夹中的内容
hdfs dfs -ls -R / 复制本地文件至HDFS put或copyFromLocal命令, 使用-f强制覆盖HDFS中已存在的文件
touch aaa.txt hdfs dfs -put aaa.txt /dir1 # hdfs dfs -copyFromLocal aaa.txt /dir1 hdfs dfs -ls -R / 获取HDFS中的文件  get / copyToLocal: 将单个文件复制至本地  # rm aaa.txt hdfs dfs -get /dir1/aaa.txt ~ # hdfs dfs -copyToLocal /dir1/aaa.txt ~ ls -al getmerge: 将多个文件存入本地的同一个文件中  touch a.</description>
    </item>
    
    <item>
      <title>Hadoop 完全分布式安装</title>
      <link>https://blog.fifcom.cn/posts/hadoop-distributed-install/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0800</pubDate>
      
      <guid>https://blog.fifcom.cn/posts/hadoop-distributed-install/</guid>
      <description>基本环境准备 配置Java环境 编辑/etc/profile:
export JAVA_HOME=/usr/local/jdk1.8/ export JRE_HOME=/usr/local/jdk1.8/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile
配置hosts 三台机器都要配置，以便于免密登录 编辑/etc/hosts:
master_ip_here master slave1_ip_here slave1 slave2_ip_here slave2 配置免密登录  在所有节点上生成rsa公钥和私钥: ssh-keygen -t rsa  将slave节点上生成的公钥用scp命令传到master节点上：  scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1 scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2 3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：
cd ~/.ssh cat id_rsa.pub &amp;gt;&amp;gt; authorized_keys cat id_rsa.pub.slave1 &amp;gt;&amp;gt; authorized_keys cat id_rsa.pub.slave2 &amp;gt;&amp;gt; authorized_keys 将master上的authorized_keys用scp命令传到slave节点上：  scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys 测试免密登录：  ssh master ssh slave1 ssh slave2 Hadoop配置 配置Java路径 在master上编辑hadoop-env.</description>
    </item>
    
    <item>
      <title>Hadoop 伪分布式安装</title>
      <link>https://blog.fifcom.cn/posts/hadoop-pseudo-distributed-install/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0800</pubDate>
      
      <guid>https://blog.fifcom.cn/posts/hadoop-pseudo-distributed-install/</guid>
      <description>环境配置  三台机器上都安装JDK环境: 可以使用包管理工具一键安装，也可以上传JDK安装包，解压后配置环境变量即可  yum -y install java-1.8.0-openjdk* # 不推荐 或者
tar -zxvf OpenJDK8U-jdk_x64_linux_openj9_linuxXL_8u282b08_openj9-0.24.0.tar.gz -C /opt vi /etc/profile # 在文件下方添加 export JAVA_HOME=/opt/jdk8u282-b08 export JRE_HOME=/opt/jdk8u282-b08/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar # 输入:wq!退出 source /etc/profile # 使用环境变量配置 安装Hadoop环境: 首先上传安装包，再解压至opt目录  tar -zxvf hadoop-2.9.2.tar.gz -C /opt hadoop前提配置  配置master节点  首先进入安装目录, 编辑脚本:
cd /opt/hadoop-2.9.2/etc/hadoop vi hadoop-env.sh # 找到`# The java implementation to use. ...`， 编辑下面的为 export JAVA_HOME=/opt/jdk8u282-b08 继续编辑当前目录下的core-site.xml文件，指定HDFS的 NameNode的地址，value值是主机名加端口号，主机使用master节点的ip地址
vi core-site.xml 在configuration标签内添加：
&amp;lt;property&amp;gt;  &amp;lt;name&amp;gt;fs.</description>
    </item>
    
  </channel>
</rss>
