<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Hadoop 完全分布式安装 | FIFCOM实验室</title><meta name=keywords content="hadoop">
<meta name=description content="基本环境准备 配置Java环境 编辑/etc/profile:
export JAVA_HOME=/usr/local/jdk1.8/ export JRE_HOME=/usr/local/jdk1.8/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile
配置hosts 三台机器都要配置，以便于免密登录 编辑/etc/hosts:
master_ip_here master slave1_ip_here slave1 slave2_ip_here slave2 配置免密登录  在所有节点上生成rsa公钥和私钥: ssh-keygen -t rsa  将slave节点上生成的公钥用scp命令传到master节点上：  scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1 scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2 3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：
cd ~/.ssh cat id_rsa.pub >> authorized_keys cat id_rsa.pub.slave1 >> authorized_keys cat id_rsa.pub.slave2 >> authorized_keys 将master上的authorized_keys用scp命令传到slave节点上：  scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys 测试免密登录：  ssh master ssh slave1 ssh slave2 Hadoop配置 配置Java路径 在master上编辑hadoop-env.">
<meta name=author content="FIFCOM">
<link rel=canonical href=https://blog.fifcom.cn/posts/hadoop-distributed-install/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<link rel=preload href="https://fifcom.cn/avatar/?transparent=1" as=image>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href="https://fifcom.cn/avatar/?transparent=1">
<link rel=icon type=image/png sizes=16x16 href="https://fifcom.cn/avatar/?transparent=1">
<link rel=icon type=image/png sizes=32x32 href="https://fifcom.cn/avatar/?transparent=1">
<link rel=apple-touch-icon href="https://fifcom.cn/avatar/?transparent=1">
<link rel=mask-icon href="https://fifcom.cn/avatar/?transparent=1">
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.93.2">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Hadoop 完全分布式安装">
<meta property="og:description" content="基本环境准备 配置Java环境 编辑/etc/profile:
export JAVA_HOME=/usr/local/jdk1.8/ export JRE_HOME=/usr/local/jdk1.8/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile
配置hosts 三台机器都要配置，以便于免密登录 编辑/etc/hosts:
master_ip_here master slave1_ip_here slave1 slave2_ip_here slave2 配置免密登录  在所有节点上生成rsa公钥和私钥: ssh-keygen -t rsa  将slave节点上生成的公钥用scp命令传到master节点上：  scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1 scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2 3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：
cd ~/.ssh cat id_rsa.pub >> authorized_keys cat id_rsa.pub.slave1 >> authorized_keys cat id_rsa.pub.slave2 >> authorized_keys 将master上的authorized_keys用scp命令传到slave节点上：  scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys 测试免密登录：  ssh master ssh slave1 ssh slave2 Hadoop配置 配置Java路径 在master上编辑hadoop-env.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://blog.fifcom.cn/posts/hadoop-distributed-install/"><meta property="og:image" content="https://fifcom.cn/avatar/?transparent=1"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-03-05T00:00:00+08:00">
<meta property="article:modified_time" content="2022-03-05T00:00:00+08:00"><meta property="og:site_name" content="FIFCOM实验室">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://fifcom.cn/avatar/?transparent=1">
<meta name=twitter:title content="Hadoop 完全分布式安装">
<meta name=twitter:description content="基本环境准备 配置Java环境 编辑/etc/profile:
export JAVA_HOME=/usr/local/jdk1.8/ export JRE_HOME=/usr/local/jdk1.8/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile
配置hosts 三台机器都要配置，以便于免密登录 编辑/etc/hosts:
master_ip_here master slave1_ip_here slave1 slave2_ip_here slave2 配置免密登录  在所有节点上生成rsa公钥和私钥: ssh-keygen -t rsa  将slave节点上生成的公钥用scp命令传到master节点上：  scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1 scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2 3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：
cd ~/.ssh cat id_rsa.pub >> authorized_keys cat id_rsa.pub.slave1 >> authorized_keys cat id_rsa.pub.slave2 >> authorized_keys 将master上的authorized_keys用scp命令传到slave节点上：  scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys 测试免密登录：  ssh master ssh slave1 ssh slave2 Hadoop配置 配置Java路径 在master上编辑hadoop-env.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.fifcom.cn/posts/"},{"@type":"ListItem","position":2,"name":"Hadoop 完全分布式安装","item":"https://blog.fifcom.cn/posts/hadoop-distributed-install/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hadoop 完全分布式安装","name":"Hadoop 完全分布式安装","description":"基本环境准备 配置Java环境 编辑/etc/profile:\nexport JAVA_HOME=/usr/local/jdk1.8/ export JRE_HOME=/usr/local/jdk1.8/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile\n配置hosts 三台机器都要配置，以便于免密登录 编辑/etc/hosts:\nmaster_ip_here master slave1_ip_here slave1 slave2_ip_here slave2 配置免密登录  在所有节点上生成rsa公钥和私钥: ssh-keygen -t rsa  将slave节点上生成的公钥用scp命令传到master节点上：  scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1 scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2 3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：\ncd ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys cat id_rsa.pub.slave1 \u0026gt;\u0026gt; authorized_keys cat id_rsa.pub.slave2 \u0026gt;\u0026gt; authorized_keys 将master上的authorized_keys用scp命令传到slave节点上：  scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys 测试免密登录：  ssh master ssh slave1 ssh slave2 Hadoop配置 配置Java路径 在master上编辑hadoop-env.","keywords":["hadoop"],"articleBody":"基本环境准备 配置Java环境 编辑/etc/profile:\nexport JAVA_HOME=/usr/local/jdk1.8/ export JRE_HOME=/usr/local/jdk1.8/jre export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar source /etc/profile\n配置hosts 三台机器都要配置，以便于免密登录 编辑/etc/hosts:\nmaster_ip_here master slave1_ip_here slave1 slave2_ip_here slave2 配置免密登录  在所有节点上生成rsa公钥和私钥: ssh-keygen -t rsa  将slave节点上生成的公钥用scp命令传到master节点上：  scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1 scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2 3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：\ncd ~/.ssh cat id_rsa.pub  authorized_keys cat id_rsa.pub.slave1  authorized_keys cat id_rsa.pub.slave2  authorized_keys 将master上的authorized_keys用scp命令传到slave节点上：  scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys 测试免密登录：  ssh master ssh slave1 ssh slave2 Hadoop配置 配置Java路径 在master上编辑hadoop-env.sh\ncd /usr/local/hadoop/etc/hadoop/ vi hadoop-env.sh = export JAVA_HOME=/usr/local/jdk1.8 编辑Hadoop配置文件  在master上配置core-site.xml  cd /usr/local/hadoop/etc/hadoop/ vi core-site.xml 在configuration标签内添加:\n \tfs.defaultFS \thdfs://master:9000   \thadoop.tmp.dir \t/usr/local/hadoop/tmp   在master上配置hdfs-site.xml  cd /usr/local/hadoop/etc/hadoop/ vi hdfs-site.xml 在configuration标签内添加:\n \tdfs.replication \t2    \tdfs.permissions \ttrue  在master上配置yarn-site.xml  cd /usr/local/hadoop/etc/hadoop/ vi yarn-site.xml 在configuration标签内添加:\n \tyarn.resourcemanager.hostname \tmaster   \tyarn.nodemanager.aux-services \tmapreduce_shuffle  在master上配置slaves  cd /usr/local/hadoop/etc/hadoop/ vi slaves 删除里面的localhost，并添加slave节点\nslave1 slave2 将编辑好的配置文件发送到slave节点  scp -r /usr/local/hadoop/etc/hadoop root@slave1:/usr/local/hadoop/etc scp -r /usr/local/hadoop/etc/hadoop root@slave2:/usr/local/hadoop/etc 配置Hadoop环境变量 在所有节点上都编辑/etc/profile，并在末尾添加：\nexport HADOOP_HOME=/usr/local/hadoop export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 保存后使用source /etc/profile让环境变量生效\n运行Hadoop 格式化namenode 在master上执行格式化命令\nhdfs namenode -format 启动相关组件  启动hdfs。在master上执行:  cd /usr/local/hadoop/sbin ./start-dfs.sh 执行后使用jps命令，应该会输出三行 2. 启动yarn\ncd /usr/local/hadoop/sbin ./start-yarn.sh 执行后使用jps命令，应该会输出四行 3. 在slave上执行jps，查看是否开成功了\n[root@slave1 ~]# jps\r610 Jps\r235 DataNode\r379 NodeManager 测试Hadoop 打开master的web界面 http://master_ip_here:50070 测试命令 hadoop fs -ls / hadoop fs -mkdir /test hadoop fs -ls / ","wordCount":"193","inLanguage":"en","datePublished":"2022-03-05T00:00:00+08:00","dateModified":"2022-03-05T00:00:00+08:00","author":{"@type":"Person","name":"FIFCOM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.fifcom.cn/posts/hadoop-distributed-install/"},"publisher":{"@type":"Organization","name":"FIFCOM实验室","logo":{"@type":"ImageObject","url":"https://fifcom.cn/avatar/?transparent=1"}}}</script>
</head><body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://blog.fifcom.cn/ accesskey=h title="FIFCOM实验室 (Alt + H)">
<img src="https://fifcom.cn/avatar/?transparent=1" alt=logo aria-label=logo height=35>FIFCOM实验室</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div><ul id=menu>
<li>
<a href=https://blog.fifcom.cn/tags/ title=标签>
<span>标签</span>
</a>
</li><li>
<a href=https://fifcom.cn/ title=主页>
<span>主页</span>
</a>
</li><li>
<a href=https://blog.fifcom.cn/tags/friends/ title=朋友们>
<span>朋友们</span>
</a>
</li></ul></nav></header><main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://blog.fifcom.cn/>Home</a>&nbsp;»&nbsp;<a href=https://blog.fifcom.cn/posts/>Posts</a></div><h1 class=post-title>
Hadoop 完全分布式安装
</h1><div class=post-meta><span title="2022-03-05 00:00:00 +0800 CST">March 5, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;FIFCOM&nbsp;|&nbsp;<a href="https://fifcom.cn/aff/?from=61c389caa31f73f1601ace6ee9ebe3ed" rel="noopener noreferrer" target=_blank>支持我</a>
</div></header><div class=post-content><h1 id=基本环境准备>基本环境准备<a hidden class=anchor aria-hidden=true href=#基本环境准备>#</a></h1><h4 id=配置java环境>配置Java环境<a hidden class=anchor aria-hidden=true href=#配置java环境>#</a></h4><p>编辑/etc/profile:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export JAVA_HOME<span style=color:#f92672>=</span>/usr/local/jdk1.8/
</span></span><span style=display:flex><span>export JRE_HOME<span style=color:#f92672>=</span>/usr/local/jdk1.8/jre
</span></span><span style=display:flex><span>export PATH<span style=color:#f92672>=</span>$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
</span></span><span style=display:flex><span>export CLASSPATH<span style=color:#f92672>=</span>.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
</span></span></code></pre></div><p><code>source /etc/profile</code></p><h4 id=配置hosts>配置hosts<a hidden class=anchor aria-hidden=true href=#配置hosts>#</a></h4><p>三台机器都要配置，以便于免密登录
编辑/etc/hosts:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>master_ip_here master
</span></span><span style=display:flex><span>slave1_ip_here slave1
</span></span><span style=display:flex><span>slave2_ip_here slave2
</span></span></code></pre></div><h4 id=配置免密登录>配置免密登录<a hidden class=anchor aria-hidden=true href=#配置免密登录>#</a></h4><ol>
<li>在所有节点上生成rsa公钥和私钥: <code>ssh-keygen -t rsa</code>
<img loading=lazy src=https://cdn.fifcom.cn/blog/9TMyD3i.png alt=ssh-keygen>
</li><li>将slave节点上生成的公钥用scp命令传到master节点上：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave1
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>scp ~/.ssh/id_rsa.pub root@master:~/.ssh/id_rsa.pub.slave2
</span></span></code></pre></div><p><img loading=lazy src=https://cdn.fifcom.cn/blog/3pY4DB4.png alt=scp>
3. 在master上生成authorized_keys，即把三个生成的公钥输入进一个文件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd ~/.ssh
</span></span><span style=display:flex><span>cat id_rsa.pub &gt;&gt; authorized_keys
</span></span><span style=display:flex><span>cat id_rsa.pub.slave1 &gt;&gt; authorized_keys
</span></span><span style=display:flex><span>cat id_rsa.pub.slave2 &gt;&gt; authorized_keys
</span></span></code></pre></div><ol start=4>
<li>将master上的authorized_keys用scp命令传到slave节点上：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys
</span></span><span style=display:flex><span>scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys
</span></span></code></pre></div><ol start=5>
<li>测试免密登录：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>ssh master
</span></span><span style=display:flex><span>ssh slave1
</span></span><span style=display:flex><span>ssh slave2
</span></span></code></pre></div><h1 id=hadoop配置>Hadoop配置<a hidden class=anchor aria-hidden=true href=#hadoop配置>#</a></h1><h4 id=配置java路径>配置Java路径<a hidden class=anchor aria-hidden=true href=#配置java路径>#</a></h4><p>在master上编辑<code>hadoop-env.sh</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/etc/hadoop/
</span></span><span style=display:flex><span>vi hadoop-env.sh
</span></span><span style=display:flex><span><span style=color:#f92672>=</span>&gt; export JAVA_HOME<span style=color:#f92672>=</span>/usr/local/jdk1.8
</span></span></code></pre></div><h4 id=编辑hadoop配置文件>编辑Hadoop配置文件<a hidden class=anchor aria-hidden=true href=#编辑hadoop配置文件>#</a></h4><ol>
<li>在master上配置core-site.xml</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/etc/hadoop/
</span></span><span style=display:flex><span>vi core-site.xml
</span></span></code></pre></div><p>在configuration标签内添加:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#f92672>&lt;property&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;name&gt;</span>fs.defaultFS<span style=color:#f92672>&lt;/name&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;value&gt;</span>hdfs://master:9000<span style=color:#f92672>&lt;/value&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/property&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;property&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;name&gt;</span>hadoop.tmp.dir<span style=color:#f92672>&lt;/name&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;value&gt;</span>/usr/local/hadoop/tmp<span style=color:#f92672>&lt;/value&gt;</span> <span style=color:#75715e>&lt;!-- 这里指的是hadoop安装目录的tmp目录 --&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/property&gt;</span>
</span></span></code></pre></div><ol start=2>
<li>在master上配置hdfs-site.xml</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/etc/hadoop/
</span></span><span style=display:flex><span>vi hdfs-site.xml
</span></span></code></pre></div><p>在configuration标签内添加:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#f92672>&lt;property&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;name&gt;</span>dfs.replication<span style=color:#f92672>&lt;/name&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;value&gt;</span>2<span style=color:#f92672>&lt;/value&gt;</span> <span style=color:#75715e>&lt;!-- 两个slave节点，所以为2 --&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/property&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;property&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;name&gt;</span>dfs.permissions<span style=color:#f92672>&lt;/name&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;value&gt;</span>true<span style=color:#f92672>&lt;/value&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/property&gt;</span>
</span></span></code></pre></div><ol start=3>
<li>在master上配置yarn-site.xml</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/etc/hadoop/
</span></span><span style=display:flex><span>vi yarn-site.xml
</span></span></code></pre></div><p>在configuration标签内添加:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#f92672>&lt;property&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;name&gt;</span>yarn.resourcemanager.hostname<span style=color:#f92672>&lt;/name&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;value&gt;</span>master<span style=color:#f92672>&lt;/value&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/property&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;property&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;name&gt;</span>yarn.nodemanager.aux-services<span style=color:#f92672>&lt;/name&gt;</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>&lt;value&gt;</span>mapreduce_shuffle<span style=color:#f92672>&lt;/value&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/property&gt;</span>
</span></span></code></pre></div><ol start=4>
<li>在master上配置slaves</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/etc/hadoop/
</span></span><span style=display:flex><span>vi slaves
</span></span></code></pre></div><p>删除里面的localhost，并添加slave节点</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span>slave1
</span></span><span style=display:flex><span>slave2
</span></span></code></pre></div><ol start=5>
<li>将编辑好的配置文件发送到slave节点</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>scp -r /usr/local/hadoop/etc/hadoop root@slave1:/usr/local/hadoop/etc
</span></span><span style=display:flex><span>scp -r /usr/local/hadoop/etc/hadoop root@slave2:/usr/local/hadoop/etc
</span></span></code></pre></div><p><img loading=lazy src=https://cdn.fifcom.cn/blog/noD7rj0.png alt=distribute>
</p><h4 id=配置hadoop环境变量>配置Hadoop环境变量<a hidden class=anchor aria-hidden=true href=#配置hadoop环境变量>#</a></h4><p>在所有节点上都编辑/etc/profile，并在末尾添加：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export HADOOP_HOME<span style=color:#f92672>=</span>/usr/local/hadoop
</span></span><span style=display:flex><span>export PATH<span style=color:#f92672>=</span>$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
</span></span></code></pre></div><p>保存后使用<code>source /etc/profile</code>让环境变量生效</p><h1 id=运行hadoop>运行Hadoop<a hidden class=anchor aria-hidden=true href=#运行hadoop>#</a></h1><h4 id=格式化namenode>格式化namenode<a hidden class=anchor aria-hidden=true href=#格式化namenode>#</a></h4><p>在master上执行格式化命令</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>hdfs namenode -format
</span></span></code></pre></div><p><img loading=lazy src=https://cdn.fifcom.cn/blog/iKwOWqs.png alt=format>
</p><h4 id=启动相关组件>启动相关组件<a hidden class=anchor aria-hidden=true href=#启动相关组件>#</a></h4><ol>
<li>启动hdfs。在master上执行:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/sbin
</span></span><span style=display:flex><span>./start-dfs.sh
</span></span></code></pre></div><p>执行后使用jps命令，应该会输出三行
<img loading=lazy src=https://cdn.fifcom.cn/blog/fByDK2K.png alt=start-dfs>
2. 启动yarn</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd /usr/local/hadoop/sbin
</span></span><span style=display:flex><span>./start-yarn.sh
</span></span></code></pre></div><p>执行后使用jps命令，应该会输出四行
<img loading=lazy src=https://cdn.fifcom.cn/blog/i1xmCaM.png alt=start-yarn>
3. 在slave上执行jps，查看是否开成功了</p><pre tabindex=0><code>[root@slave1 ~]# jps
610 Jps
235 DataNode
379 NodeManager
</code></pre><h1 id=测试hadoop>测试Hadoop<a hidden class=anchor aria-hidden=true href=#测试hadoop>#</a></h1><h4 id=打开master的web界面>打开master的web界面<a hidden class=anchor aria-hidden=true href=#打开master的web界面>#</a></h4><p>http://master_ip_here:50070
<img loading=lazy src=https://cdn.fifcom.cn/blog/PCTXGlx.png alt=web>
</p><h4 id=测试命令>测试命令<a hidden class=anchor aria-hidden=true href=#测试命令>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>hadoop fs -ls /
</span></span><span style=display:flex><span>hadoop fs -mkdir /test
</span></span><span style=display:flex><span>hadoop fs -ls /
</span></span></code></pre></div><p><img loading=lazy src=https://cdn.fifcom.cn/blog/gQcnlIT.png alt=test>
</p></div><footer class=post-footer>
<ul class=post-tags>
<li><a href=https://blog.fifcom.cn/tags/hadoop/>hadoop</a></li></ul><nav class=paginav>
<a class=prev href=https://blog.fifcom.cn/posts/hadoop-commands/>
<span class=title>« Prev Page</span>
<br>
<span>Hadoop 常用命令</span>
</a>
<a class=next href=https://blog.fifcom.cn/posts/hadoop-pseudo-distributed-install/>
<span class=title>Next Page »</span>
<br>
<span>Hadoop 伪分布式安装</span>
</a>
</nav><div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Hadoop 完全分布式安装 on twitter" href="https://twitter.com/intent/tweet/?text=Hadoop%20%e5%ae%8c%e5%85%a8%e5%88%86%e5%b8%83%e5%bc%8f%e5%ae%89%e8%a3%85&url=https%3a%2f%2fblog.fifcom.cn%2fposts%2fhadoop-distributed-install%2f&hashtags=hadoop"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Hadoop 完全分布式安装 on telegram" href="https://telegram.me/share/url?text=Hadoop%20%e5%ae%8c%e5%85%a8%e5%88%86%e5%b8%83%e5%bc%8f%e5%ae%89%e8%a3%85&url=https%3a%2f%2fblog.fifcom.cn%2fposts%2fhadoop-distributed-install%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div></footer></article></main><footer class=footer>
<span>&copy; 2022 <a href=https://blog.fifcom.cn/>FIFCOM实验室</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script>
<script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script>
</body></html>